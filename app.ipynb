{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import os\n",
    "from keras.layers import Dense, Embedding, Flatten, Dropout\n",
    "from keras.models import Sequential\n",
    "from keras.activations import sigmoid\n",
    "from keras.metrics import Accuracy\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.utils import pad_sequences\n",
    "from gtts import gTTS\n",
    "from time import sleep\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returns the lengths of each file for the name generator\n",
    "length_dict = {}\n",
    "for file in os.listdir(\"curate\"):\n",
    "    path = os.path.join(\"curate\", file)\n",
    "    f = open(path)\n",
    "    length_dict[file] = len(f.readlines())\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Name Generator\n",
    "train_names = []\n",
    "num_names = 100000\n",
    "name_indices = random.sample(range(51075960), num_names)\n",
    "name_indices.sort()\n",
    "sum = 0\n",
    "i = -1\n",
    "for index in name_indices:\n",
    "    while sum < index:\n",
    "        i += 1\n",
    "        f = open(os.path.join(\"curate\", list(length_dict.keys())[i]))\n",
    "        current = f.readlines()\n",
    "        f.close()\n",
    "        sum += list(length_dict.values())[i]\n",
    "    train_names.append(current[sum-index].split(\",\")[slice(2)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Word Generator\n",
    "train_words = []\n",
    "num_words = 200000\n",
    "word_indices = random.sample(range(466550), num_words)\n",
    "f = open(\"english.txt\")\n",
    "lines = f.readlines()\n",
    "f.close()\n",
    "for index in word_indices:\n",
    "    train_words.append(lines[index][:-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mixing Datasets\n",
    "train_labels = np.concatenate((np.ones(2*num_names), np.zeros(num_words)))\n",
    "train_inputs = []\n",
    "for item in train_names:\n",
    "    train_inputs.extend([item[0], item[1]])\n",
    "train_inputs.extend(train_words)\n",
    "train_df = np.stack((train_labels, train_inputs), axis=-1)\n",
    "np.random.shuffle(train_df)\n",
    "train_labels = np.array([item[0] for item in train_df]).astype(float)\n",
    "train_inputs = np.array([item[1] for item in train_df])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Tokenization\n",
    "maxlen=4\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(train_inputs)\n",
    "train_inputs = np.array(pad_sequences(tokenizer.texts_to_sequences(train_inputs), maxlen=maxlen))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=sigmoid))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"binary_crossentropy\")\n",
    "\n",
    "history = model.fit(x=train_inputs, y=train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Validation on Words\n",
    "f = open(\"validation.txt\")\n",
    "samples = [item[:-1] for item in f.readlines()]\n",
    "f.close()\n",
    "input = pad_sequences(tokenizer.texts_to_sequences(samples), maxlen=maxlen)\n",
    "out = [item[0] for item in list(map(np.round, list(model.predict(input))))]\n",
    "sum = 0\n",
    "for i in range(1000):\n",
    "    if out[i] == 1:\n",
    "        sum += 1\n",
    "print(sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#AI TTS\n",
    "string = \"\"\n",
    "number = float(model.predict(pad_sequences(tokenizer.texts_to_sequences([string]), maxlen=maxlen))[0])\n",
    "text = f'I am {round(number*100)} percent sure that {string} is a name.'\n",
    "  \n",
    "tts = gTTS(text=text, lang=\"en\")\n",
    "\n",
    "tts.save(\"predict.mp3\")\n",
    "\n",
    "os.system(\"open predict.mp3\")\n",
    "\n",
    "sleep(4)\n",
    "\n",
    "os.system(\"rm predict.mp3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Weights\n",
    "model.save_weights('weights2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Weights\n",
    "model.load_weights('weights1')\n",
    "\n",
    "'''\n",
    "Model Code:\n",
    "1 - Embedding Layer Approach:\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 32, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Dense(1, activation=sigmoid))\n",
    "2 - Same as above, but counters overfitting:\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length=maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(1, activation=sigmoid))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Save Tokenizer\n",
    "with open('tokenizer.pickle', 'wb') as f:\n",
    "    pickle.dump(tokenizer, f, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.12 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
